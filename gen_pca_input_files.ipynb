{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e141d9ee-8f20-4739-a10c-4b4514ab687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "IN_PATH = \"all_metrics_standarized.csv\"\n",
    "OUT_A = \"input_pca_set_A_.csv\"\n",
    "OUT_B = \"input_pca_set_B_.csv\"\n",
    "\n",
    "desired_A_display = [\n",
    "    \"spike sync\",\n",
    "    \"assembly variety\",\n",
    "    \"cv\",\n",
    "    \"cv2\",\n",
    "    \"fano factor\",\n",
    "    \"isi distance\",\n",
    "    \"largest assembly\",\n",
    "    \"max cluster\",\n",
    "    \"mean firing rate\",\n",
    "    \"spike contrast\",\n",
    "]\n",
    "\n",
    "desired_B_display = [\n",
    "    \"assembly variety\",\n",
    "    \"cv\",\n",
    "    \"fano factor\",\n",
    "    \"isi distance\",\n",
    "    \"largest assembly\",\n",
    "    \"max cluster\",\n",
    "    \"mean firing rate\",\n",
    "    \"spike contrast\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf16ee49-c30f-44aa-82ec-ffba29c0b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _norm(s: str) -> str:\n",
    "    return \"\".join(ch for ch in s.lower() if ch.isalnum())\n",
    "\n",
    "alias_normalized = {\n",
    "    \"pikesync\": \"spikesync\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "626a897e-e84c-4d19-8672-f20e86509f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_actual_lookup(actual_cols):\n",
    "    norm_to_actual = {}\n",
    "    for c in actual_cols:\n",
    "        n = _norm(c)\n",
    "        norm_to_actual.setdefault(n, c)\n",
    "    return norm_to_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3a5e7d7-bf7d-4966-ac93-bbf7d519f143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resolve_columns(desired_display, actual_cols):\n",
    "    norm_to_actual = _build_actual_lookup(actual_cols)\n",
    "    resolved = []\n",
    "    missing = []\n",
    "\n",
    "    for name in desired_display:\n",
    "        n = _norm(name)\n",
    "        n = _norm(alias_normalized.get(n, n))\n",
    "        if n in norm_to_actual:\n",
    "            resolved.append(norm_to_actual[n])\n",
    "        else:\n",
    "            snake_guess = name.strip().lower().replace(\" \", \"_\")\n",
    "            n2 = _norm(snake_guess)\n",
    "            if n2 in norm_to_actual:\n",
    "                resolved.append(norm_to_actual[n2])\n",
    "            else:\n",
    "                missing.append(name)\n",
    "\n",
    "    return resolved, missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8be170-176a-426b-b390-189c2b35ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _verify_columns(filepath, desired_display):\n",
    "    df_check = pd.read_csv(filepath, nrows=0)  # read only header\n",
    "    cols = list(df_check.columns)\n",
    "    resolved_against_written, missing = _resolve_columns(desired_display, cols)\n",
    "\n",
    "    order_match = resolved_against_written == cols\n",
    "    content_match = set(_norm(c) for c in resolved_against_written) == set(_norm(c) for c in cols)\n",
    "\n",
    "    return {\n",
    "        \"file\": filepath,\n",
    "        \"written_columns\": cols,\n",
    "        \"resolved_from_desired\": resolved_against_written,\n",
    "        \"missing_from_desired\": missing,\n",
    "        \"order_match\": order_match,\n",
    "        \"content_match\": content_match,\n",
    "    }\n",
    "\n",
    "if not os.path.exists(IN_PATH):\n",
    "    print(f\"ERROR: Input file not found: {IN_PATH}\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "df = pd.read_csv(IN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415bcd81-299b-4021-82f9-a2cd4e414179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved input_pca_set_A_.csv with columns (in order): ['spike_sync', 'assembly_variety', 'cv', 'cv2', 'fano_factor', 'isi_distance', 'largest_assembly', 'max_cluster', 'mean_firing_rate', 'spike_contrast']\n"
     ]
    }
   ],
   "source": [
    "resolved_A, missing_A = _resolve_columns(desired_A_display, df.columns)\n",
    "if missing_A:\n",
    "    print(\"ERROR: The following requested Set A columns could not be found in the input (after normalization/aliases):\")\n",
    "    for m in missing_A:\n",
    "        print(f\"  - {m}\")\n",
    "    print(\"\\nAvailable columns in input:\")\n",
    "    for c in df.columns:\n",
    "        print(f\"  - {c}\")\n",
    "    sys.exit(2)\n",
    "\n",
    "df_A = df[resolved_A].copy()\n",
    "df_A.to_csv(OUT_A, index=False)\n",
    "print(f\"Saved {OUT_A} with columns (in order): {resolved_A}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6189e842-a4d4-40b3-8c44-90b6df79198f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved input_pca_set_B_.csv with columns (in order): ['assembly_variety', 'cv', 'fano_factor', 'isi_distance', 'largest_assembly', 'max_cluster', 'mean_firing_rate', 'spike_contrast']\n"
     ]
    }
   ],
   "source": [
    "resolved_B, missing_B = _resolve_columns(desired_B_display, df.columns)\n",
    "if missing_B:\n",
    "    print(\"ERROR: The following requested Set B columns could not be found in the input (after normalization/aliases):\")\n",
    "    for m in missing_B:\n",
    "        print(f\"  - {m}\")\n",
    "    print(\"\\nAvailable columns in input:\")\n",
    "    for c in df.columns:\n",
    "        print(f\"  - {c}\")\n",
    "    sys.exit(3)\n",
    "\n",
    "df_B = df[resolved_B].copy()\n",
    "df_B.to_csv(OUT_B, index=False)\n",
    "print(f\"Saved {OUT_B} with columns (in order): {resolved_B}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdb35898-ba49-42c5-ba66-d2d9a91ec4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying written files against the requested lists...\n",
      "\n",
      "[Set A] input_pca_set_A_.csv\n",
      "  Columns written: ['spike_sync', 'assembly_variety', 'cv', 'cv2', 'fano_factor', 'isi_distance', 'largest_assembly', 'max_cluster', 'mean_firing_rate', 'spike_contrast']\n",
      "  Order matches requested list? YES\n",
      "  Content matches requested set (ignoring order)? YES\n",
      "\n",
      "[Set B] input_pca_set_B_.csv\n",
      "  Columns written: ['assembly_variety', 'cv', 'fano_factor', 'isi_distance', 'largest_assembly', 'max_cluster', 'mean_firing_rate', 'spike_contrast']\n",
      "  Order matches requested list? YES\n",
      "  Content matches requested set (ignoring order)? YES\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/gits/pca-notebook/venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerifying written files against the requested lists...\")\n",
    "\n",
    "report_A = _verify_columns(OUT_A, desired_A_display)\n",
    "report_B = _verify_columns(OUT_B, desired_B_display)\n",
    "\n",
    "def _print_report(tag, report):\n",
    "    print(f\"\\n[{tag}] {report['file']}\")\n",
    "    print(f\"  Columns written: {report['written_columns']}\")\n",
    "    if report[\"missing_from_desired\"]:\n",
    "        print(f\"  Missing (unresolved) from requested list: {report['missing_from_desired']}\")\n",
    "    print(f\"  Order matches requested list? {'YES' if report['order_match'] else 'NO'}\")\n",
    "    print(f\"  Content matches requested set (ignoring order)? {'YES' if report['content_match'] else 'NO'}\")\n",
    "    if not report[\"order_match\"]:\n",
    "        print(\"  NOTE: If this says NO but 'content' says YES, the file still has all requested columns but order differs.\")\n",
    "\n",
    "_print_report(\"Set A\", report_A)\n",
    "_print_report(\"Set B\", report_B)\n",
    "\n",
    "exit_code = 0\n",
    "if (not report_A[\"content_match\"]) or (not report_B[\"content_match\"]) or (not report_A[\"order_match\"]) or (not report_B[\"order_match\"]):\n",
    "    exit_code = 4\n",
    "\n",
    "sys.exit(exit_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
